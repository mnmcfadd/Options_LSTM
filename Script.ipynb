{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data: \n",
    "Option prices and implied volatility from post-no-preference option chain dataset. data spans from 2019-current. collected more recently on mon-wed-fri. Many but not all options are posted there for each security.\n",
    "\n",
    "AAPL price data from Kaggle(?)\n",
    "\n",
    "Treasury Bond rates from home.treasury.gov. Daily treasury par yield rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#10m rows takes about 30 seconds... Expect long processing times for full data. do in batches.\n",
    "#f10m = pd.read_csv('pnp_options.csv', nrows=10000000)\n",
    "\n",
    "f1m = pd.read_csv('pnp_options.csv', usecols=['date', 'act_symbol', 'expiration', 'strike', 'call_put', 'bid', 'ask',\n",
    "       'vol'] ,nrows = 1000000)\n",
    "\n",
    "prices = pd.read_csv('HistoricalQuotes.csv')\n",
    "\n",
    "rates = pd.read_csv('treasury_2019.csv', usecols=['Date', '1 Mo', '2 Mo', '3 Mo', '6 Mo', '1 Yr'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE...\n",
    "\n",
    "**The following data engineering assumes**:\n",
    "\n",
    "1. we are only interested in AAPL options. if we want to expand, we can simply modify the first line to include more act_symbol values\n",
    "\n",
    "2. our prices dataframe includes prices covering the entire range of dates for option prices, plus an extra n_prices before the earliest option price, such that we can utilize the n_prices preceding the option pricing in our LSTM model down the line \n",
    "\n",
    "3. our rates dataframe also contains treasury rates with dates covering all issuance dates of options.\n",
    "    \n",
    "4. all of our option time-to-expiries are closest to 1-3 months, not 6+ months. in the 1m row data the longest time-to-expiry is 62 days. if we see in the full data a time-to-expiry longer than 135 days, we need to add an option to use the 6 month treasury rate in our determine_r function.\n",
    "\n",
    "\n",
    "**Also**, you will probably want to split this cell into multiple smaller ones when we're working with the full data. some of the actions might be computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/49/x210g1j14bs717pp0q4xf3zr0000gq/T/ipykernel_24743/2456644849.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['days_expiry'] = (pd.to_datetime(df['expiration']) - pd.to_datetime(df['date'])).dt.days\n"
     ]
    }
   ],
   "source": [
    "df = f1m[f1m['act_symbol'] == 'AAPL']\n",
    "aapl_prices = prices.copy()\n",
    "rate = rates.copy()\n",
    "\n",
    "#remove expiration date, replace with int # of days until expiration\n",
    "df['days_expiry'] = (pd.to_datetime(df['expiration']) - pd.to_datetime(df['date'])).dt.days\n",
    "df = df.drop(['expiration'], axis=1)\n",
    "\n",
    "#format dates on df, aapl_prices, rates to match each other\n",
    "\n",
    "df['date'] = pd.to_numeric(df['date'].str.replace('-',''))\n",
    "aapl_prices['Date'] = pd.to_datetime(aapl_prices['Date'], format='%m/%d/%Y').dt.strftime('%Y-%m-%d')\n",
    "aapl_prices['Date'] = pd.to_numeric(aapl_prices['Date'].str.replace('-',''))\n",
    "rate['Date'] = pd.to_datetime(rate['Date'], format='%m/%d/%Y').dt.strftime('%Y-%m-%d')\n",
    "rate['Date'] = pd.to_numeric(rate['Date'].str.replace('-',''))\n",
    "\n",
    "#merge rate with df on date, using forward/backwards fill approach, as some dates of options and treasury prices do not line up...\n",
    "rate_reindexed = rate.set_index('Date').reindex(df['date'])\n",
    "rate_reindexed = rate_reindexed.ffill().bfill()\n",
    "df = pd.merge(df, rate_reindexed, left_on='date', right_index=True, how='left')\n",
    "\n",
    "#choose risk free rate 'r', based on which treasury rate matures closest to the expiration date of the option.\n",
    "#Then drop other treasury columns leaving just 'r'\n",
    "def determine_r(row):\n",
    "    if row['days_expiry'] < 45:\n",
    "        return row['1 Mo']\n",
    "    elif 45 <= row['days_expiry'] < 75:\n",
    "        return row['2 Mo']\n",
    "    else:\n",
    "        return row['3 Mo']\n",
    "\n",
    "df['r'] = df.apply(determine_r, axis=1)\n",
    "df = df.drop(['1 Mo', '2 Mo', '3 Mo', '6 Mo', '1 Yr'], axis=1)\n",
    "\n",
    "#Now to the price dataframe...\n",
    "\n",
    "#create df with n_prices + 1 columns. first column indicating the date on the last pricing. other n_prices columns will be the n_prices leading up to the current date.\n",
    "#then we will merge again on date, using most recent closing price preceding option pricing.\n",
    "n = 10\n",
    "#obtain df of all prices needed for last_n_prices df... and convert closing price to decimal type\n",
    "minDateIndex = aapl_prices.index[aapl_prices['Date'] == min(df['date'])-1].tolist()[0]\n",
    "maxDateIndex = aapl_prices.index[aapl_prices['Date'] == max(df['date'])-1].tolist()[0]\n",
    "prices_all = aapl_prices.loc[maxDateIndex:(minDateIndex+n),].sort_values(by=['Date'])\n",
    "prices_all[' Close/Last'] = prices_all[' Close/Last'].str.replace('$', '').astype(float)\n",
    "prices_all = prices_all.drop([' Volume', ' Open', ' High', ' Low'], axis=1)\n",
    "\n",
    "stepData = []\n",
    "for i in range(len(prices_all) - n):\n",
    "    date = prices_all['Date'].iloc[i + n] \n",
    "    n_prices = prices_all[' Close/Last'].iloc[i:i + n + 1].tolist() \n",
    "    stepData.append([date] + n_prices)\n",
    "columns = ['Date'] + [f't{i+1}' for i in range(n)] + ['currentP']\n",
    "lastn_prices = pd.DataFrame(stepData, columns=columns)\n",
    "\n",
    "df = pd.merge_asof(df, lastn_prices, left_on='date', right_on='Date', direction='backward')\n",
    "\n",
    "#Create column for 'fair price' of option, just average of bid and ask... then drop out the rows not being used in this first iteration...\n",
    "df['option_fp'] = (df['ask'] + df['bid'])/2\n",
    "inputs_df = df.drop(['date', 'act_symbol', 'bid', 'ask', 'vol', 'Date'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing Train/Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strike</th>\n",
       "      <th>call_put</th>\n",
       "      <th>days_expiry</th>\n",
       "      <th>r</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "      <th>t6</th>\n",
       "      <th>t7</th>\n",
       "      <th>t8</th>\n",
       "      <th>t9</th>\n",
       "      <th>t10</th>\n",
       "      <th>currentP</th>\n",
       "      <th>option_fp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145.0</td>\n",
       "      <td>Call</td>\n",
       "      <td>13</td>\n",
       "      <td>2.42</td>\n",
       "      <td>157.76</td>\n",
       "      <td>156.3</td>\n",
       "      <td>154.68</td>\n",
       "      <td>165.25</td>\n",
       "      <td>166.44</td>\n",
       "      <td>166.52</td>\n",
       "      <td>171.25</td>\n",
       "      <td>174.18</td>\n",
       "      <td>174.24</td>\n",
       "      <td>170.94</td>\n",
       "      <td>170.41</td>\n",
       "      <td>25.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145.0</td>\n",
       "      <td>Call</td>\n",
       "      <td>13</td>\n",
       "      <td>2.42</td>\n",
       "      <td>157.76</td>\n",
       "      <td>156.3</td>\n",
       "      <td>154.68</td>\n",
       "      <td>165.25</td>\n",
       "      <td>166.44</td>\n",
       "      <td>166.52</td>\n",
       "      <td>171.25</td>\n",
       "      <td>174.18</td>\n",
       "      <td>174.24</td>\n",
       "      <td>170.94</td>\n",
       "      <td>170.41</td>\n",
       "      <td>25.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145.0</td>\n",
       "      <td>Call</td>\n",
       "      <td>13</td>\n",
       "      <td>2.42</td>\n",
       "      <td>157.76</td>\n",
       "      <td>156.3</td>\n",
       "      <td>154.68</td>\n",
       "      <td>165.25</td>\n",
       "      <td>166.44</td>\n",
       "      <td>166.52</td>\n",
       "      <td>171.25</td>\n",
       "      <td>174.18</td>\n",
       "      <td>174.24</td>\n",
       "      <td>170.94</td>\n",
       "      <td>170.41</td>\n",
       "      <td>25.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145.0</td>\n",
       "      <td>Call</td>\n",
       "      <td>13</td>\n",
       "      <td>2.42</td>\n",
       "      <td>157.76</td>\n",
       "      <td>156.3</td>\n",
       "      <td>154.68</td>\n",
       "      <td>165.25</td>\n",
       "      <td>166.44</td>\n",
       "      <td>166.52</td>\n",
       "      <td>171.25</td>\n",
       "      <td>174.18</td>\n",
       "      <td>174.24</td>\n",
       "      <td>170.94</td>\n",
       "      <td>170.41</td>\n",
       "      <td>25.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145.0</td>\n",
       "      <td>Call</td>\n",
       "      <td>13</td>\n",
       "      <td>2.42</td>\n",
       "      <td>157.76</td>\n",
       "      <td>156.3</td>\n",
       "      <td>154.68</td>\n",
       "      <td>165.25</td>\n",
       "      <td>166.44</td>\n",
       "      <td>166.52</td>\n",
       "      <td>171.25</td>\n",
       "      <td>174.18</td>\n",
       "      <td>174.24</td>\n",
       "      <td>170.94</td>\n",
       "      <td>170.41</td>\n",
       "      <td>25.675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   strike call_put  days_expiry     r      t1     t2      t3      t4      t5  \\\n",
       "0   145.0     Call           13  2.42  157.76  156.3  154.68  165.25  166.44   \n",
       "1   145.0     Call           13  2.42  157.76  156.3  154.68  165.25  166.44   \n",
       "2   145.0     Call           13  2.42  157.76  156.3  154.68  165.25  166.44   \n",
       "3   145.0     Call           13  2.42  157.76  156.3  154.68  165.25  166.44   \n",
       "4   145.0     Call           13  2.42  157.76  156.3  154.68  165.25  166.44   \n",
       "\n",
       "       t6      t7      t8      t9     t10  currentP  option_fp  \n",
       "0  166.52  171.25  174.18  174.24  170.94    170.41     25.675  \n",
       "1  166.52  171.25  174.18  174.24  170.94    170.41     25.675  \n",
       "2  166.52  171.25  174.18  174.24  170.94    170.41     25.675  \n",
       "3  166.52  171.25  174.18  174.24  170.94    170.41     25.675  \n",
       "4  166.52  171.25  174.18  174.24  170.94    170.41     25.675  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#y is option_fp\n",
    "#train and test calls and puts seperately (obviously)\n",
    "display(inputs_df.head())\n",
    "\n",
    "call_df = inputs_df[inputs_df['call_put'] == \"Call\"]\n",
    "call_df = call_df.drop(['call_put'], axis=1)\n",
    "put_df = inputs_df[inputs_df['call_put'] == \"Put\"]\n",
    "put_df = put_df.drop(['call_put'], axis=1)\n",
    "\n",
    "CALL_X_train, CALL_X_test, CALL_Y_train, CALL_Y_test = train_test_split(call_df.drop(['option_fp'], axis=1).values, call_df['option_fp'].values, \n",
    "                                                                        test_size=.1, random_state=1)\n",
    "\n",
    "PUT_X_train, PUT_X_test, PUT_Y_train, PUT_Y_test = train_test_split(put_df.drop(['option_fp'], axis=1).values, put_df['option_fp'].values, \n",
    "                                                                        test_size=.1, random_state=1)\n",
    "\n",
    "#print(CALL_X_train)\n",
    "#print(CALL_Y_train)\n",
    "#for input to LSTM-MLP, must split inputs into state inputs (for LSTM), and non-state inputs. We can pass the state inputs seperately through the\n",
    "#LSTM, then take the LSTM output and concatenate it with the remaining non-state inputs. Thus we must split the inputs into two list elements,\n",
    "#the first of which being a list of state-inputs (all price data), the second of which being a list of the remaining inputs.\n",
    "\n",
    "#Note... Should we put the current asset price as part of the state inputs, or the non-state inputs?? try both....\n",
    "#let's start with putting all pricing info in the state:\n",
    "CALL_X_train = [CALL_X_train[:,3:].reshape(CALL_X_train.shape[0],n+1,1), CALL_X_train[:,:3]]\n",
    "CALL_X_test = [CALL_X_test[:,3:].reshape(CALL_X_test.shape[0],n+1,1), CALL_X_test[:,:3]]\n",
    "PUT_X_train = [PUT_X_train[:,3:].reshape(PUT_X_train.shape[0],n+1,1), PUT_X_train[:,:3]]\n",
    "PUT_X_test = [PUT_X_test[:,3:].reshape(PUT_X_test.shape[0],n+1,1), PUT_X_test[:,:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 4\n",
    "features = 3\n",
    "n_batch = 4096\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building LSTM-MLP Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Activation, LeakyReLU, BatchNormalization, LSTM, Bidirectional, Input, Concatenate\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "\n",
    "def make_model():\n",
    "    close_history = Input((n+1, 1))\n",
    "    input2 = Input((features,))\n",
    "    \n",
    "    lstm = Sequential()\n",
    "    lstm.add(LSTM(units=8, input_shape=(n+1, 1), return_sequences=True))\n",
    "    lstm.add(LSTM(units=8, return_sequences=True))\n",
    "    lstm.add(LSTM(units=8, return_sequences=True))\n",
    "    lstm.add(LSTM(units=8, return_sequences=False))\n",
    "    input1 = lstm(close_history)\n",
    "    \n",
    "    connect = Concatenate()([input1, input2])\n",
    "    \n",
    "    for _ in range(layers - 1):\n",
    "        connect = Dense(100)(connect)\n",
    "        connect = BatchNormalization()(connect)\n",
    "        connect = LeakyReLU()(connect)\n",
    "    \n",
    "    predict = Dense(1, activation='relu')(connect)\n",
    "\n",
    "    return Model(inputs=[close_history, input2], outputs=predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,952</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │ leaky_re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │ leaky_re_lu_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │ leaky_re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │      \u001b[38;5;34m1,952\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ sequential_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │      \u001b[38;5;34m1,200\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │        \u001b[38;5;34m400\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m10,100\u001b[0m │ leaky_re_lu_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │        \u001b[38;5;34m400\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m10,100\u001b[0m │ leaky_re_lu_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │        \u001b[38;5;34m400\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m101\u001b[0m │ leaky_re_lu_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,653</span> (96.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,653\u001b[0m (96.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,053</span> (93.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,053\u001b[0m (93.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> (2.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m600\u001b[0m (2.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "call_model = make_model()\n",
    "call_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 166ms/step - loss: 44.1166 - val_loss: 140.7040\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 41.8735 - val_loss: 127.3271\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 41.3952 - val_loss: 96.1940\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 40.9006 - val_loss: 50.6137\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 41.6699 - val_loss: 55.9326\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 41.5289 - val_loss: 59.9196\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 41.2971 - val_loss: 52.7966\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 41.2307 - val_loss: 50.6133\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 41.1577 - val_loss: 48.6825\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 41.1455 - val_loss: 49.6182\n"
     ]
    }
   ],
   "source": [
    "call_model.compile(optimizer=Adam(learning_rate=1e-2), loss='mse')\n",
    "history = call_model.fit(CALL_X_train, CALL_Y_train, \n",
    "                    batch_size=n_batch, epochs=10, \n",
    "                    validation_split = 0.01,\n",
    "                    callbacks=[TensorBoard()],\n",
    "                    verbose=1)\n",
    "call_model.save('saved-models/call_test1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 142ms/step - loss: 41.3735 - val_loss: 49.4480\n",
      "Epoch 2/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - loss: 41.3144 - val_loss: 47.9436\n",
      "Epoch 3/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - loss: 40.8607 - val_loss: 35.1794\n",
      "Epoch 4/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 22.0012 - val_loss: 204.1225\n",
      "Epoch 5/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 16.4962 - val_loss: 76.1326\n"
     ]
    }
   ],
   "source": [
    "call_model.compile(optimizer=Adam(learning_rate=1e-3), loss='mse')\n",
    "history = call_model.fit(CALL_X_train, CALL_Y_train, \n",
    "                    batch_size=n_batch, epochs=5, \n",
    "                    validation_split = 0.01,\n",
    "                    callbacks=[TensorBoard()],\n",
    "                    verbose=1)\n",
    "call_model.save('saved-models/call_test2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 192ms/step - loss: 14.9334 - val_loss: 82.6164\n",
      "Epoch 2/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 14.7362 - val_loss: 71.6061\n",
      "Epoch 3/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 14.8981 - val_loss: 65.7977\n",
      "Epoch 4/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - loss: 14.6859 - val_loss: 54.9057\n",
      "Epoch 5/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - loss: 14.3615 - val_loss: 49.1139\n"
     ]
    }
   ],
   "source": [
    "call_model.compile(optimizer=Adam(learning_rate=1e-4), loss='mse')\n",
    "history = call_model.fit(CALL_X_train, CALL_Y_train, \n",
    "                    batch_size=n_batch, epochs=5, \n",
    "                    validation_split = 0.01,\n",
    "                    callbacks=[TensorBoard()],\n",
    "                    verbose=1)\n",
    "call_model.save('saved-models/call_test3.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
